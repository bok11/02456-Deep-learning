{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credits\n",
    "\n",
    "This is heavily influenced or copied from https://github.com/pytorch/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is PyTorch?\n",
    "\n",
    "> **NOTE** In the last part of this lab cuda is used. If you have a cuda enabled machine, read the README.md in the root of this repo on how to use nvidia-docker.\n",
    "\n",
    "\n",
    "It’s a Python based scientific computing package targeted at two sets of\n",
    "audiences:\n",
    "-  A replacement for numpy to use the power of GPUs\n",
    "-  a deep learning research platform that provides maximum flexibility\n",
    "   and speed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "In this lab you will get a quick start on what pytorch is and how to use it.\n",
    "\n",
    "## 1. Tensors\n",
    "\n",
    "Tensors are similar to numpy’s ndarrays, with the addition being that\n",
    "Tensors can also be used on a GPU to accelerate computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a 5x3 matrix, uninitialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.6742e+19, 3.0756e-41, 5.7453e-44],\n",
      "        [0.0000e+00,        nan, 0.0000e+00],\n",
      "        [1.3733e-14, 6.4076e+07, 2.0706e-19],\n",
      "        [7.3909e+22, 2.4176e-12, 1.1625e+33],\n",
      "        [8.9605e-01, 1.1632e+33, 5.6003e-02]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a randomly initialized matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2641, 0.6887, 0.0562],\n",
      "        [0.5656, 0.2232, 0.8009],\n",
      "        [0.1723, 0.5200, 0.2870],\n",
      "        [0.0709, 0.6406, 0.4079],\n",
      "        [0.7797, 0.8896, 0.6748]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** `torch.Size` is in fact a tuple, so it supports the same operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2641, 0.6887, 0.0562],\n",
      "        [2.0000, 2.0000, 2.0000],\n",
      "        [2.0000, 2.0000, 2.0000],\n",
      "        [0.0709, 0.6406, 0.4079],\n",
      "        [0.7797, 0.8896, 0.6748]])\n"
     ]
    }
   ],
   "source": [
    "x[1:3] = 2\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "1. Make a tensor of size (2, 17)\n",
    "2. Make a torch.FloatTensor of size (3, 1)\n",
    "3. Make a torch.LongTensor of size (5, 2, 1)\n",
    "  - fill the entire tensor with 7s\n",
    "4. Make a torch.ByteTensor of size (5,)\n",
    "  - fill the middle 3 indices with ones such that it records [0, 1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4455, 0.7030, 0.3774, 0.0725, 0.9566, 0.5424, 0.2236, 0.0501, 0.4140,\n",
      "         0.3619, 0.3682, 0.1487, 0.3752, 0.4694, 0.0815, 0.2656, 0.4446],\n",
      "        [0.7791, 0.6347, 0.8299, 0.5237, 0.1301, 0.5214, 0.7383, 0.8351, 0.3166,\n",
      "         0.9007, 0.7631, 0.5815, 0.5498, 0.9321, 0.0524, 0.1503, 0.3904]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(2,17)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6173e+25],\n",
      "        [4.5685e-41],\n",
      "        [9.6940e+19]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.FloatTensor(3,1)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[140026291030984],\n",
      "         [ 94267567292032]],\n",
      "\n",
      "        [[140025452174944],\n",
      "         [ 94267563823696]],\n",
      "\n",
      "        [[    -4294967296],\n",
      "         [              3]],\n",
      "\n",
      "        [[              0],\n",
      "         [              3]],\n",
      "\n",
      "        [[140025466962400],\n",
      "         [              0]]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.LongTensor(5,2,1)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[7],\n",
      "         [7]],\n",
      "\n",
      "        [[7],\n",
      "         [7]],\n",
      "\n",
      "        [[7],\n",
      "         [7]],\n",
      "\n",
      "        [[7],\n",
      "         [7]],\n",
      "\n",
      "        [[7],\n",
      "         [7]]])\n"
     ]
    }
   ],
   "source": [
    "tensor[0:len(x)]=7\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.zeros(5).byte()\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 1, 0], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "tensor[1:4] = 1\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Operations\n",
    "There are multiple syntaxes for operations. Let's see addition as an example:\n",
    "\n",
    "### 2.1 Addition: syntax 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2218, 1.2875, 0.9194],\n",
      "        [2.3241, 2.5200, 2.8325],\n",
      "        [2.0052, 2.5369, 2.7121],\n",
      "        [0.5299, 1.4049, 0.7879],\n",
      "        [1.0330, 1.7673, 1.1282]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Addition: syntax 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2218, 1.2875, 0.9194],\n",
      "        [2.3241, 2.5200, 2.8325],\n",
      "        [2.0052, 2.5369, 2.7121],\n",
      "        [0.5299, 1.4049, 0.7879],\n",
      "        [1.0330, 1.7673, 1.1282]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Addition: giving an output tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2218, 1.2875, 0.9194],\n",
      "        [2.3241, 2.5200, 2.8325],\n",
      "        [2.0052, 2.5369, 2.7121],\n",
      "        [0.5299, 1.4049, 0.7879],\n",
      "        [1.0330, 1.7673, 1.1282]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.Tensor(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Addition: in-place\n",
    "\n",
    "adds `x`to `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2218, 1.2875, 0.9194],\n",
      "        [2.3241, 2.5200, 2.8325],\n",
      "        [2.0052, 2.5369, 2.7121],\n",
      "        [0.5299, 1.4049, 0.7879],\n",
      "        [1.0330, 1.7673, 1.1282]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** Any operation that mutates a tensor in-place is post-fixed with an `_`. For example: `x.copy_(y)`, `x.t_()`, will change `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use standard numpy-like indexing with all bells and whistles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6887, 2.0000, 2.0000, 0.6406, 0.8896])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read later** 100+ Tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc are described here <http://pytorch.org/docs/torch>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "1. multiply of two tensors (see [torch.Tensor.mul](http://pytorch.org/docs/master/tensors.html#torch.Tensor.mul))\n",
    "2. do the same, but inplace\n",
    "3. division of two tensors (see [torch.Tensor.div](http://pytorch.org/docs/master/tensors.html#torch.Tensor.div))\n",
    "4. perform a matrix multiplication of two tensors of size (2, 4) and (4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0852,  0.6106,  0.0029],\n",
       "        [ 9.2963, 10.0800, 11.3298],\n",
       "        [ 8.0208, 10.1476, 10.8486],\n",
       "        [ 0.0027,  0.5765,  0.1311],\n",
       "        [ 0.6281,  1.3988,  0.5138]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mul(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3227, 0.8867, 0.0516],\n",
       "        [4.6481, 5.0400, 5.6649],\n",
       "        [4.0104, 5.0738, 5.4243],\n",
       "        [0.0376, 0.9000, 0.3214],\n",
       "        [0.8055, 1.5723, 0.7614]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mul_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2218, 1.2875, 0.9194],\n",
       "        [2.3241, 2.5200, 2.8325],\n",
       "        [2.0052, 2.5369, 2.7121],\n",
       "        [0.5299, 1.4049, 0.7879],\n",
       "        [1.0330, 1.7673, 1.1282]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.div(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2218, 1.2875, 0.9194],\n",
       "        [2.3241, 2.5200, 2.8325],\n",
       "        [2.0052, 2.5369, 2.7121],\n",
       "        [0.5299, 1.4049, 0.7879],\n",
       "        [1.0330, 1.7673, 1.1282]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.div_(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5).byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-e07cf2c61c6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2,4)\n",
    "b = torch.rand(4,2)\n",
    "a.mul(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Numpy Bridge\n",
    "\n",
    "Converting a torch Tensor to a numpy array and vice versa is a breeze.\n",
    "\n",
    "The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other.\n",
    "\n",
    "### 3.1 Converting torch Tensor to numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the numpy array changed in value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[ 2.  2.  2.  2.  2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Converting numpy Array to torch Tensor\n",
    "\n",
    "See how changing the np array changed the torch Tensor automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  2.  2.  2.  2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "1. create a tensor of size (5, 2) containing ones\n",
    "2. now convert it to a numpy array\n",
    "3. now convert it back to a torch tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the Tensors on the CPU except a CharTensor support converting to NumPy and back.\n",
    "\n",
    "## 4 CUDA Tensors\n",
    "\n",
    "Tensors can be moved onto GPU using the `.cuda` function.\n",
    "This is not necessary, but check the `README.md` for details on how to use a GPU with docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2641, 0.6887, 0.0562],\n",
      "        [2.0000, 2.0000, 2.0000],\n",
      "        [2.0000, 2.0000, 2.0000],\n",
      "        [0.0709, 0.6406, 0.4079],\n",
      "        [0.7797, 0.8896, 0.6748]], device='cuda:0')\n",
      "tensor([[1.2218, 1.2875, 0.9194],\n",
      "        [2.3241, 2.5200, 2.8325],\n",
      "        [2.0052, 2.5369, 2.7121],\n",
      "        [0.5299, 1.4049, 0.7879],\n",
      "        [1.0330, 1.7673, 1.1282]], device='cuda:0')\n",
      "tensor([[1.4859, 1.9761, 0.9756],\n",
      "        [4.3241, 4.5200, 4.8325],\n",
      "        [4.0052, 4.5369, 4.7121],\n",
      "        [0.6008, 2.0455, 1.1958],\n",
      "        [1.8128, 2.6570, 1.8030]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = x + y\n",
    "    # notice that the tensors are now of type torch.cuda.FloatTensor (notice the cuda in there)\n",
    "    # this is meant as a tensor to be run on the GPU.\n",
    "    # the .cuda() does this to any parameter it is applied to\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(z)\n",
    "else:\n",
    "    print(\"CUDA not available on your machie.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
